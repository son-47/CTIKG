import logging
import re
import os
import litellm  # T·∫≠n d·ª•ng th∆∞ vi·ªán c√≥ s·∫µn c·ªßa d·ª± √°n
from neo4j import GraphDatabase

logger = logging.getLogger(__name__)

class Neo4jLoader:
    def __init__(self, uri, user, password, database="neo4j", embedding_model=None):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        self.database = database
        
        # T·∫≠n d·ª•ng model m·∫∑c ƒë·ªãnh c·ªßa d·ª± √°n n·∫øu kh√¥ng truy·ªÅn v√†o
        # M·∫∑c ƒë·ªãnh CTINexus d√πng 'text-embedding-3-large' ho·∫∑c l·∫•y t·ª´ ENV
        self.embedding_model = embedding_model or os.getenv("EMBEDDING_MODEL", "text-embedding-3-large")
        
        # C·∫•u h√¨nh cho Ollama/Local n·∫øu c·∫ßn (gi·ªëng logic trong graph_constructor.py)
        self.api_base = os.getenv("OLLAMA_BASE_URL", None)
        if "llama" in self.embedding_model or "nomic" in self.embedding_model:
             if not self.embedding_model.startswith("ollama/"):
                self.embedding_model = f"ollama/{self.embedding_model}"

        logger.info(f"üîå Neo4jLoader s·ª≠ d·ª•ng model embedding: {self.embedding_model}")
        
        self.verify_connection()
        self.create_initial_constraints_and_indexes()

    def close(self):
        self.driver.close()

    def verify_connection(self):
        try:
            self.driver.verify_connectivity()
        except Exception as e:
            logger.error(f"‚ùå L·ªói k·∫øt n·ªëi Neo4j: {e}")
            raise

    def create_initial_constraints_and_indexes(self):
        """
        T·∫°o Index Vector v√† Constraints
        """
        with self.driver.session(database=self.database) as session:
            # 1. Constraints (T√≠nh duy nh·∫•t)
            session.run("CREATE CONSTRAINT entity_name_unique IF NOT EXISTS FOR (e:Entity) REQUIRE e.name IS UNIQUE")
            session.run("CREATE CONSTRAINT report_id_unique IF NOT EXISTS FOR (r:Report) REQUIRE r.name IS UNIQUE")
            
            # 2. Vector Index (T√¨m ki·∫øm t∆∞∆°ng ƒë·ªìng)
            # L∆∞u √Ω: dimensions ph·∫£i kh·ªõp v·ªõi model. OpenAI large l√† 3072, Ada-002 l√† 1536.
            # Ta ƒë·ªÉ m·∫∑c ƒë·ªãnh 1536 (th∆∞·ªùng d√πng) ho·∫∑c 3072. N·∫øu sai Neo4j s·∫Ω b√°o l·ªói khi insert.
            # ·ªû ƒë√¢y ta gi·∫£ ƒë·ªãnh model tr·∫£ v·ªÅ 1536 ho·∫∑c 3072, Neo4j 5.x t·ª± ƒë·ªông check.
            # Tuy nhi√™n, c·∫ßn l∆∞u √Ω: B·∫°n ph·∫£i x√≥a index c≈© n·∫øu ƒë·ªïi model c√≥ chi·ªÅu vector kh√°c.
            try:
                session.run("""
                    CREATE VECTOR INDEX entity_embeddings IF NOT EXISTS
                    FOR (e:Entity) ON (e.embedding)
                    OPTIONS {indexConfig: {
                     `vector.dimensions`: 3072, 
                     `vector.similarity_function`: 'cosine'
                    }}
                """)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o Vector Index (c√≥ th·ªÉ do phi√™n b·∫£n Neo4j c≈© ho·∫∑c ƒë√£ t·ªìn t·∫°i kh√°c config): {e}")

    def _get_embedding(self, text):
        """
        T·∫≠n d·ª•ng LiteLLM ƒë·ªÉ l·∫•y vector, gi·ªëng h·ªát c√°ch Merger c·ªßa CTINexus l√†m.
        """
        try:
            # G·ªçi API qua litellm (h·ªó tr·ª£ OpenAI, Azure, Ollama...)
            response = litellm.embedding(
                model=self.embedding_model,
                input=[text],
                api_base=self.api_base
            )
            return response["data"][0]["embedding"]
        except Exception as e:
            logger.error(f"L·ªói khi t·∫°o embedding cho '{text}': {e}")
            return None

    def _normalize_label(self, label):
        if not label: return "Entity"
        return re.sub(r'[^a-zA-Z0-9]', '_', label)

    def _normalize_relation(self, relation_text):
        if not relation_text: return "RELATED_TO"
        return re.sub(r'\s+', '_', relation_text.strip()).upper()

    def ingest_report(self, cti_result, report_name="Unknown_Report"):
        ea_triplets = cti_result.get("EA", {}).get("aligned_triplets", [])
        lp_links = cti_result.get("LP", {}).get("predicted_links", [])
        
        all_triplets = []
        for t in ea_triplets:
            t['is_predicted'] = False
            all_triplets.append(t)
        for t in lp_links:
            t['is_predicted'] = True
            all_triplets.append(t)

        with self.driver.session(database=self.database) as session:
            session.execute_write(self._process_batch, all_triplets, report_name)

    def _process_batch(self, tx, triplets, report_name):
        # 1. V·∫´n t·∫°o Node Report (ƒë·ªÉ l∆∞u metadata nh∆∞ ng√†y gi·ªù ingest), nh∆∞ng KH√îNG n·ªëi c·∫°nh
        # Node n√†y ch·ªâ d√πng ƒë·ªÉ qu·∫£n l√Ω danh s√°ch c√°c b√°o c√°o ƒë√£ n·∫°p
        tx.run("""
            MERGE (r:Report {name: $report_name})
            ON CREATE SET r.ingested_at = datetime()
        """, report_name=report_name)

        for item in triplets:
            subj = item.get("subject", {})
            obj = item.get("object", {})
            relation = item.get("relation", "RELATED_TO")
            is_predicted = item.get("is_predicted", False)

            s_name = subj.get("entity_text", "Unknown")
            s_type = self._normalize_label(subj.get("mention_class"))
            o_name = obj.get("entity_text", "Unknown")
            o_type = self._normalize_label(obj.get("mention_class"))
            rel_type = self._normalize_relation(relation)

            # T·∫°o embedding (gi·ªØ nguy√™n logic c≈©)
            s_emb = self._get_embedding(s_name)
            o_emb = self._get_embedding(o_name)

            # --- LOGIC T·ªêI ∆ØU ---
            # Thay v√¨ t·∫°o quan h·ªá MENTIONED_IN, ta c·∫≠p nh·∫≠t thu·ªôc t√≠nh 'sources' 
            # tr√™n m·ªëi quan h·ªá ch√≠nh.
            
            cypher_query = f"""
            // 1. X·ª≠ l√Ω Subject (T√¨m ki·∫øm vector ho·∫∑c merge t√™n)
            MERGE (s:Entity {{name: $s_name}})
            ON CREATE SET s.type = $s_type, s.embedding = $s_emb
            SET s:{s_type}

            // 2. X·ª≠ l√Ω Object
            MERGE (o:Entity {{name: $o_name}})
            ON CREATE SET o.type = $o_type, o.embedding = $o_emb
            SET o:{o_type}

            // 3. X·ª≠ l√Ω Link & Ngu·ªìn g·ªëc (Provenance)
            MERGE (s)-[r:`{rel_type}`]->(o)
            
            // N·∫øu quan h·ªá m·ªõi t·∫°o: Kh·ªüi t·∫°o danh s√°ch ngu·ªìn
            ON CREATE SET 
                r.is_predicted = $is_predicted, 
                r.weight = 1,
                r.sources = [$report_name],       // <--- L∆∞u t√™n report v√†o list
                r.last_seen = datetime()

            // N·∫øu quan h·ªá ƒë√£ c√≥: C·∫≠p nh·∫≠t th√™m ngu·ªìn v√†o danh s√°ch (n·∫øu ch∆∞a c√≥)
            ON MATCH SET 
                r.weight = r.weight + 1,
                r.last_seen = datetime(),
                r.sources = CASE 
                    WHEN NOT $report_name IN r.sources THEN r.sources + $report_name 
                    ELSE r.sources 
                END
            """

            tx.run(cypher_query, 
                   s_name=s_name, s_type=s_type, s_emb=s_emb,
                   o_name=o_name, o_type=o_type, o_emb=o_emb,
                   is_predicted=is_predicted, report_name=report_name)